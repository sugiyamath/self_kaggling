m
[0.70786517 0.73033708 0.73033708 0.80898876 0.85393258 0.76404494
 0.84269663 0.78409091 0.82954545 0.82954545]
              precision    recall  f1-score   support

           0       0.80      0.83      0.82       131
           1       0.74      0.70      0.72        91

    accuracy                           0.78       222
   macro avg       0.77      0.77      0.77       222
weighted avg       0.78      0.78      0.78       222


m
[0.85393258 0.83146067 0.7752809  0.86516854 0.83146067 0.79775281
 0.80898876 0.78409091 0.86363636 0.82954545]
              precision    recall  f1-score   support

           0       0.82      0.95      0.88       131
           1       0.91      0.70      0.80        91

    accuracy                           0.85       222
   macro avg       0.87      0.83      0.84       222
weighted avg       0.86      0.85      0.85       222


model3
[0.84269663 0.84269663 0.79775281 0.85393258 0.80898876 0.82022472
 0.78651685 0.78409091 0.88636364 0.85227273]
              precision    recall  f1-score   support

           0       0.82      0.95      0.88       131
           1       0.91      0.70      0.80        91

    accuracy                           0.85       222
   macro avg       0.87      0.83      0.84       222
weighted avg       0.86      0.85      0.85       222


model4
[0.84269663 0.86516854 0.79775281 0.87640449 0.82022472 0.82022472
 0.80898876 0.78409091 0.875      0.85227273]
              precision    recall  f1-score   support

           0       0.84      0.95      0.89       131
           1       0.92      0.74      0.82        91

    accuracy                           0.86       222
   macro avg       0.88      0.85      0.85       222
weighted avg       0.87      0.86      0.86       222


